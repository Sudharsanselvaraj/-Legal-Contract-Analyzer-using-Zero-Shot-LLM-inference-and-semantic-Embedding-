# -*- coding: utf-8 -*-
"""Legal Contract Analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h-yTmztZQbOqcVZspmy7MUDRvrETZiCQ
"""

!pip install kagglehub kaggle -q
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
import kagglehub
dataset_path = kagglehub.dataset_download("changethan/legal-contract-dataset")
print("üìÅ Dataset downloaded to:", dataset_path)
!unzip -q {dataset_path}/*.zip -d legal_contract_dataset

import os
dataset_dir = "/kaggle/input/legal-contract-dataset"
print(" Files inside the dataset folder:")
print(os.listdir(dataset_dir))

import pandas as pd
df = pd.read_csv('/kaggle/input/legal-contract-dataset/all_reshaped_clauses.csv')
print(f"Shape: {df.shape}")
print("Columns:", df.columns.tolist())
df.head()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['clause_type'])
print(f"Total unique labels: {len(label_encoder.classes_)}")

from sklearn.model_selection import train_test_split

# Split dataset
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['clause_text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42)

print(f"Training Samples: {len(train_texts)}")
print(f"Validation Samples: {len(val_texts)}")

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv('/kaggle/input/legal-contract-dataset/all_reshaped_clauses.csv')

label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['clause_type'])

train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['clause_text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42)

!pip install sentence-transformers imbalanced-learn xgboost -q

from sentence_transformers import SentenceTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler
import pandas as pd

df = pd.read_csv('/kaggle/input/legal-contract-dataset/all_reshaped_clauses.csv')
df = df[['clause_text', 'clause_type']].dropna()

le = LabelEncoder()
df['label'] = le.fit_transform(df['clause_type'])

train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['clause_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)


model = SentenceTransformer('all-MiniLM-L6-v2')
X_train = model.encode(train_texts.tolist(), show_progress_bar=True)
X_val = model.encode(val_texts.tolist(), show_progress_bar=True)

ros = RandomOverSampler()
X_train_bal, y_train_bal = ros.fit_resample(X_train, train_labels)

clf = RandomForestClassifier(n_estimators=300, max_depth=25)
clf.fit(X_train_bal, y_train_bal)

y_pred = clf.predict(X_val)
print("Accuracy:", accuracy_score(val_labels, y_pred))
print(classification_report(val_labels, y_pred, target_names=le.classes_))

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download("stopwords")
nltk.download("wordnet")

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = re.sub(r'\W+', ' ', text)  # Remove special characters
    text = text.lower()
    text = " ".join([lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words])
    return text

df['clean_clause'] = df['clause_text'].apply(clean_text)

from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")  # Light, accurate
X = model.encode(df['clean_clause'].tolist(), show_progress_bar=True)

!pip install xgboost -q

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.utils.class_weight import compute_sample_weight
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier

df = pd.read_csv('/kaggle/input/legal-contract-dataset/all_reshaped_clauses.csv')
df.dropna(subset=['clause_text', 'clause_type'], inplace=True)


from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['label'] = le.fit_transform(df['clause_type'])

X_train, X_val, y_train, y_val = train_test_split(df['clause_text'], df['label'], test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_val_vec = vectorizer.transform(X_val)

sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)

xgb = XGBClassifier(
    objective='multi:softmax',
    num_class=len(le.classes_),
    eval_metric='mlogloss',
    use_label_encoder=False,
    max_depth=10,
    n_estimators=250,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    tree_method='hist',  # Use 'gpu_hist' if GPU
    random_state=42
)

xgb.fit(X_train_vec, y_train, sample_weight=sample_weights)

preds = xgb.predict(X_val_vec)
print("Accuracy:", accuracy_score(y_val, preds))
print(classification_report(y_val, preds, target_names=le.classes_))

!pip install PyMuPDF

doc = fitz.open("Autonomous_Proctoring_Report.pdf")
for page in doc:
    print(f"--- Page {page.number + 1} ---\n")
    print(page.get_text())

!pip install reportlab

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
import textwrap

def generate_pdf_report(report_data, output_path="output_report.pdf"):
    c = canvas.Canvas(output_path, pagesize=A4)
    width, height = A4
    y = height - 50

    # Title
    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, y, "üìë Autonomous Contract Clause Risk Assessment Report")
    y -= 40

    # Set font for body
    c.setFont("Helvetica", 10)

    for item in report_data:
        if y < 120:
            c.showPage()
            y = height - 50
            c.setFont("Helvetica", 10)

        # Clause header
        c.setFont("Helvetica-Bold", 11)
        c.drawString(50, y, f"Clause {item['Clause #']}: {item['Predicted Type']} | {item['Risk']} | Sim: {item['Similarity Score']}")
        y -= 18

        # Clause preview
        wrapped_text = textwrap.wrap(item['Clause Text'], width=110)
        c.setFont("Helvetica", 9)
        for line in wrapped_text:
            c.drawString(60, y, line)
            y -= 12
            if y < 100:
                c.showPage()
                y = height - 50
                c.setFont("Helvetica", 9)

        y -= 12  # spacing between clauses

    c.save()
    print(f"‚úÖ Report saved to: {output_path}")